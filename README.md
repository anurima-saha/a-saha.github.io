# **CREATING WEBISTE FOR WEB ASSIGNMENT DUE 08-30-2023**

### CONTENTS (questions from assignment):
3. Introduce ONE selected “Data Set” from the [awesome-datascience] GitHub with its
URL and describe its potential applications and values.
4. Introduce ONE selected “free-data-science-book” with its URL and author/institute
information. Explain briefly why you are interested in this book.

### ***3.DATASET:***
[NASA-Socioeconomic Data and Applications Center (sedac)](https://sedac.ciesin.columbia.edu/)
###### ***APPLICATION & VALUE***
The data collection in this NASA website looks something like this:
![image](https://github.com/anurima-saha/a-saha.github.io/assets/142840970/7ea228e4-856b-4dbd-bfde-548bb36adab2)

We can see a wide collection ranging from population to food supply, from environmental performance indicator to census related archives, from climate risk to sustainablity and so on. Data from this website will be exteremely useful for any analysis involving impact of climate change and initiatives on sustainablity.
Following [the Paris Agreement](https://unfccc.int/process-and-meetings/the-paris-agreement) by United Nations this field has become the focus for countries and industries alike, with major implications especially for finance and tech industries. So, for a person like me who is motivated to work on "Business Risk and Climate Analysis" this data holds a lot of significance.


### ***4.BOOK:***
[Computer Age Statistical Inference:Algorithms, Evidence and Data Science](https://hastie.su.domains/CASI/)
Cambridge University Press
Authrors: Bradley Efron & Trevor Hastie
###### ***POINT OF INTEREST***
To be a "data scientist" in the true sense of the term, it is of primary importance to be a skilled statistican besides being an adept coder. This book provides an all-encompassing idea of statistics going back to roots starting with classical inferential theories(Bayesian, frequentist, Fisherian). Getting the foundation right is absolutely necessary to understand more complex concepts like random forest or neural network, which is also covered by this book. Through this text we can time travel through the development of data science to what it is today, meanwhile integrating " methodology and algorithms with statistical inference". Last but not least, this book tries to provide an overview of what the future might look like for statistics and data science, which makes it an even more intersting read.
